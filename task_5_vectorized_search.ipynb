{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../dataset_2.csv', chunksize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/appuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "class Searcher():\n",
    "    def __init__(self, data, search_type, b=0.75, k=2, texts=None, inv_index=None):\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "        self.punctuation = string.punctuation + '…' + '«' + '»' + '—'\n",
    "        self.stop_words = stopwords.words('russian')\n",
    "        self.use_lemmatization = search_type == 'bm25_lemm'\n",
    "        self.search_type = search_type\n",
    "\n",
    "        self.vectorizer = fasttext.load_model(\"/home/appuser/infosearch/cc.ru.300.bin\") if search_type == 'vec' else None\n",
    "\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "\n",
    "        self.data = data # исходные данные\n",
    "\n",
    "        if texts is None:\n",
    "            print('Preprocessing texts...')\n",
    "            if search_type != 'vec':\n",
    "                self.texts = data.text.progress_apply(self.preprocess_text) # очищенные тексты в нормальной форме\n",
    "            else:\n",
    "                self.texts = data.text\n",
    "        else:\n",
    "            self.texts = texts\n",
    "\n",
    "        if inv_index is None:\n",
    "            print('Counting inverted index...')\n",
    "            \n",
    "            if search_type != 'vec':\n",
    "                inv_index = {}\n",
    "\n",
    "                for doc_id, doc in enumerate(tqdm(self.texts)):\n",
    "                    tokens = doc.split()\n",
    "                    for token in tokens:\n",
    "                        if token in inv_index:\n",
    "                            inv_index[token].add(doc_id)\n",
    "                        else:\n",
    "                            inv_index[token] = set([doc_id])\n",
    "\n",
    "            else:\n",
    "                texts_vectorized = np.zeros([len(self.texts), self.vectorizer.get_dimension()])\n",
    "                for doc_id, doc in enumerate(tqdm(self.texts)):\n",
    "                    texts_vectorized[doc_id] = self.vectorizer[str(doc)]\n",
    "\n",
    "                inv_index = faiss.IndexFlatL2(texts_vectorized.shape[1])\n",
    "                inv_index.add(texts_vectorized)\n",
    "\n",
    "                faiss.write_index(inv_index, os.path.join('/home/appuser/infosearch', \"vec.index\"))\n",
    "        \n",
    "        self.inv_index = inv_index\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        tokens = str(text).lower().translate(str.maketrans('', '', self.punctuation)).split()\n",
    "        res = ''\n",
    "\n",
    "        if self.use_lemmatization:\n",
    "            for token in tokens:\n",
    "                p = self.morph.parse(token)[0].normal_form\n",
    "                if p not in self.stop_words:\n",
    "                    res += ' ' + p\n",
    "        else:\n",
    "            for token in tokens:\n",
    "                if token not in self.stop_words:\n",
    "                    res += ' ' + token\n",
    "        \n",
    "        return res\n",
    "\n",
    "\n",
    "    def idf(self, terms, documents, eps=-0.01):\n",
    "        idfs = np.asarray([len(documents) / (len(self.inv_index[term]) + eps) for term in terms])\n",
    "        return np.log(idfs)\n",
    "\n",
    "\n",
    "    def tf(self, terms, doc_ids):\n",
    "        # можно посплитить текст в init и не сплитить каждый раз\n",
    "        def count(text):\n",
    "            freqs = dict.fromkeys(terms, 0)\n",
    "            text = text.split() \n",
    "            for term in text:\n",
    "                if term in freqs.keys():\n",
    "                    freqs[term] += 1\n",
    "            \n",
    "            return np.asarray([term_freq[1] for term_freq in freqs.items()]) / len(text)\n",
    "\n",
    "        docs = self.texts[doc_ids]\n",
    "\n",
    "        return np.stack(docs.apply(count).values)\n",
    "    \n",
    "    def tf_idf(self, terms, documents):\n",
    "        tf_scores = self.tf(terms, documents)\n",
    "        idf_scores = self.idf(terms, documents)\n",
    "\n",
    "        scores = tf_scores * idf_scores\n",
    "        return scores\n",
    "\n",
    "    def bm25(self, terms, documents):\n",
    "        \n",
    "        tf_scores = self.tf(terms, documents)\n",
    "        idf_scores = self.idf(terms, documents)\n",
    "        lens = self.texts[documents].apply(lambda x: len(x.split())).to_numpy()\n",
    "\n",
    "        scores = np.zeros(lens.shape)\n",
    "        for i, term in enumerate(terms):\n",
    "            a = (tf_scores[:, i] * (self.k + 1))\n",
    "            b = (tf_scores[:, i] + self.k * (1 - self.b + self.b * lens / lens.mean()))\n",
    "            c = idf_scores[i]\n",
    "            scores += a / b * c\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def search(self, query):\n",
    "        if self.search_type != 'vec':\n",
    "            terms = self.preprocess_text(query).split()\n",
    "\n",
    "            global_ids = set()\n",
    "            for term in terms:\n",
    "                global_ids.update(self.inv_index[term])\n",
    "\n",
    "            global_ids = np.asarray(list(global_ids))\n",
    "            scores = self.bm25(terms, global_ids)#.sum(axis=1)\n",
    "\n",
    "            local_ids = np.argsort(scores, axis=0).squeeze() # сортируем документы по возрастанию tf-idf\n",
    "            \n",
    "\n",
    "            return self.data.iloc[global_ids[local_ids][-10:]]\n",
    "        \n",
    "        else:\n",
    "            query_vector = self.vectorizer[query]\n",
    "\n",
    "            distances, indicies = self.inv_index.search(np.expand_dims(query_vector, 0), 10)\n",
    "\n",
    "            print(distances)\n",
    "            print(indicies[0])\n",
    "\n",
    "            return self.data.iloc[indicies[0]]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing texts...\n",
      "Counting inverted index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 97.22it/s]\n"
     ]
    }
   ],
   "source": [
    "s = Searcher(dataset, search_type='vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2019951 1.2022532 1.2029874 1.2032571 1.2037507 1.2041138 1.2043403\n",
      "  1.2049005 1.205671  1.2059832]]\n",
      "[52 16 37  7 88 85 89 92 32  9]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>Педокомпания</td>\n",
       "      <td>/wiki/%D0%9F%D0%B5%D0%B4%D0%BE%D0%BA%D0%BE%D0%...</td>\n",
       "      <td>Педокомпания (англ. Pedopals) — создана на 7ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Расово</td>\n",
       "      <td>/wiki/%D0%A0%D0%B0%D1%81%D0%BE%D0%B2%D0%BE</td>\n",
       "      <td>Расово (moon. 人種的に)— одно из любимых изречений...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Бобёр-извращенец</td>\n",
       "      <td>/wiki/%D0%91%D0%BE%D0%B1%D1%91%D1%80-%D0%B8%D0...</td>\n",
       "      <td>В реку случился несанкционированный выброс виа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Поцреот</td>\n",
       "      <td>/wiki/%D0%9F%D0%BE%D1%86%D1%80%D0%B5%D0%BE%D1%82</td>\n",
       "      <td>мы… рода Рускаго: Карлы Инегелдъ Фарлофъ Верем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>Довольно слабый петух</td>\n",
       "      <td>/wiki/%D0%94%D0%BE%D0%B2%D0%BE%D0%BB%D1%8C%D0%...</td>\n",
       "      <td>Довольно слабый петух — характеристика для пет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>Похрюкивалка</td>\n",
       "      <td>/wiki/%D0%9F%D0%BE%D1%85%D1%80%D1%8E%D0%BA%D0%...</td>\n",
       "      <td>Похрюкивалка — распространённое название для с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>Лев</td>\n",
       "      <td>/wiki/%D0%9B%D0%B5%D0%B2</td>\n",
       "      <td>Лев — мощное рычало котовой направленности; де...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>Потявкун</td>\n",
       "      <td>/wiki/%D0%9F%D0%BE%D1%82%D1%8F%D0%B2%D0%BA%D1%...</td>\n",
       "      <td>Потявкун (Погавкун) — народное название для со...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Жывотнайе</td>\n",
       "      <td>/wiki/%D0%96%D1%8B%D0%B2%D0%BE%D1%82%D0%BD%D0%...</td>\n",
       "      <td>Жывотнайе (жыготнайе, жыготное, жывтоне) — низ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Быдло</td>\n",
       "      <td>/wiki/%D0%91%D1%8B%D0%B4%D0%BB%D0%BE</td>\n",
       "      <td>Будь проще — шути больше— Заветы всего быдла  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                  title  \\\n",
       "52          52           Педокомпания   \n",
       "16          16                 Расово   \n",
       "37          37       Бобёр-извращенец   \n",
       "7            7                Поцреот   \n",
       "88          88  Довольно слабый петух   \n",
       "85          85           Похрюкивалка   \n",
       "89          89                    Лев   \n",
       "92          92               Потявкун   \n",
       "32          32              Жывотнайе   \n",
       "9            9                  Быдло   \n",
       "\n",
       "                                                 link  \\\n",
       "52  /wiki/%D0%9F%D0%B5%D0%B4%D0%BE%D0%BA%D0%BE%D0%...   \n",
       "16         /wiki/%D0%A0%D0%B0%D1%81%D0%BE%D0%B2%D0%BE   \n",
       "37  /wiki/%D0%91%D0%BE%D0%B1%D1%91%D1%80-%D0%B8%D0...   \n",
       "7    /wiki/%D0%9F%D0%BE%D1%86%D1%80%D0%B5%D0%BE%D1%82   \n",
       "88  /wiki/%D0%94%D0%BE%D0%B2%D0%BE%D0%BB%D1%8C%D0%...   \n",
       "85  /wiki/%D0%9F%D0%BE%D1%85%D1%80%D1%8E%D0%BA%D0%...   \n",
       "89                           /wiki/%D0%9B%D0%B5%D0%B2   \n",
       "92  /wiki/%D0%9F%D0%BE%D1%82%D1%8F%D0%B2%D0%BA%D1%...   \n",
       "32  /wiki/%D0%96%D1%8B%D0%B2%D0%BE%D1%82%D0%BD%D0%...   \n",
       "9                /wiki/%D0%91%D1%8B%D0%B4%D0%BB%D0%BE   \n",
       "\n",
       "                                                 text  \n",
       "52  Педокомпания (англ. Pedopals) — создана на 7ch...  \n",
       "16  Расово (moon. 人種的に)— одно из любимых изречений...  \n",
       "37  В реку случился несанкционированный выброс виа...  \n",
       "7   мы… рода Рускаго: Карлы Инегелдъ Фарлофъ Верем...  \n",
       "88  Довольно слабый петух — характеристика для пет...  \n",
       "85  Похрюкивалка — распространённое название для с...  \n",
       "89  Лев — мощное рычало котовой направленности; де...  \n",
       "92  Потявкун (Погавкун) — народное название для со...  \n",
       "32  Жывотнайе (жыготнайе, жыготное, жывтоне) — низ...  \n",
       "9   Будь проще — шути больше— Заветы всего быдла  ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.search('быдло')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymorphy_fast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
